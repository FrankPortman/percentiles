{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as N\n",
    "import pandas as P"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Let's Talk About Percentiles\n",
    "\n",
    "The purpose of this notebook is to illustrate some of the unintuitive but profoundly impactful statistics of percentile estimation.\n",
    "\n",
    "It's obvious to most engineers how important percentiles are to operating services. But it's not obvious how dramatically results can differ depending on how percentiles are calculated.\n",
    "\n",
    "Using theory and some real world examples, I'll try to demonstrate why percentile statistics behave so unintuitively and how subtle differences in method can profoundly impact your numbers. In the process, I'll offer some pointers for avoiding these pitfalls."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In which we define an SLA\n",
    "\n",
    "Let's start with a common problem—measuring latency.\n",
    "\n",
    "Suppose service x advertises that it can serve requests with a p99 of 100ms. That's not bad! They prove this to you by showing you a grafana dashboard that might look something like this:\n",
    "\n",
    "<img src=\"grafana.png\" width=50% height=50%>\n",
    "\n",
    "We all know dashboards never lie so you take their word for it. You shake hands on the proposed SLA and began to integrate against their service.\n",
    "\n",
    "Since you're a responsible engineer, however, you instrument calls to their service anyway. What you see surprises you—their p99s are actually far higher than what their dashboard reports, and often exceeds their SLA!\n",
    "\n",
    "Angrily, you stomp over to their pod and show them your findings.\n",
    "\n",
    "\"It must be network overhead or something wrong with your instrumentation,\" they respond, which just makes your blood boil.\n",
    "\n",
    "\"My instrumentation is perfect,\" you respond. \"The problem is your service.\"\n",
    "\n",
    "It turns out you're both wrong. The culprit was actually math."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Dataset\n",
    "The rest of this notebook will transform and sample latency numbers to supplement theory, so we use this section to generate and analyze the dataset.\n",
    "\n",
    "Since I'm too lazy to collect actual latency numbers, I'm going to make the assumption that latencies follow a power law distribution—that is, there's a long tail of very slow latencies.\n",
    "\n",
    "In reality, this is a good enough model of real world latencies for our purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = P.DataFrame(N.random.power(0.2, 100000) * 110).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have a dataframe with 1 million latencies, a max of 110 ms distributed via the power law. Let's see how that looks in a histogram:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x1149422d0>]], dtype=object)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEICAYAAAC0+DhzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x114930150>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about its median and p99?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>18.306192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>27.649308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99%</th>\n",
       "      <td>104.750100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>109.990000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0\n",
       "count  100000.000000\n",
       "mean       18.306192\n",
       "std        27.649308\n",
       "min         0.000000\n",
       "50%         3.400000\n",
       "99%       104.750100\n",
       "max       109.990000"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(percentiles=[.99])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Law of Large Numbers\n",
    "\n",
    "Before we continue with our story, let's review some stats.\n",
    "\n",
    "You may recall from school that there's a handy thing called the [Law of large numbers](https://en.wikipedia.org/wiki/Law_of_large_numbers). The LLN basically says this: The average of a large enough sample will be pretty close to the \"real\" average, give or take some error.\n",
    "\n",
    "This is pretty handy for measuring a lot of things—it means that even a relatively small sample can give us a pretty good measure of the population average.\n",
    "\n",
    "Let's test this on our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    17.3088\n",
       "dtype: float64"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(50).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not bad. Even with a sample of .05% of the population, we got a pretty close estimate of population mean.\n",
    "\n",
    "Could've been a fluke. Let's do this procedure 75 more times:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    18.386895\n",
       "dtype: float64"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_samples = P.DataFrame([df.sample(50).mean() for _ in range(1000)])\n",
    "mean_samples.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice, the average of all of our sample averages is pretty damn close to the real average. This is the law of large numbers in action!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Percentiles are trickier\n",
    "\n",
    "Unfortunately, the law of large numbers doesn't apply to percentiles. As proof, let's try the same procedure, but for the 99th percentile. As a reminder, the \"real\" p99 of our dataset is this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104.75009999999995"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(df.quantile(.99))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So what happens if we get the p99 of a sample?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    94.2888\n",
       "Name: 0.99, dtype: float64"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(50).quantile(.99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hm, seems a little off. What if we repeat this procedure a bunch of times?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    95.015978\n",
       "dtype: float64"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P.DataFrame(df.sample(50).quantile(.99) for _ in range(1000)).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The average of our percentiles doesn't converge to the actual p99! The average of many percentile estimates isn't the real value, unlike with the mean.\n",
    "\n",
    "Ok, but what if we vary our sample size?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    99.787503\n",
       "dtype: float64"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 100 samples:\n",
    "P.DataFrame(df.sample(100).quantile(.99) for _ in range(1000)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    103.774149\n",
       "dtype: float64"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 500 samples:\n",
    "P.DataFrame(df.sample(500).quantile(.99) for _ in range(1000)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    104.182944\n",
       "dtype: float64"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1000 samples\n",
    "P.DataFrame(df.sample(1000).quantile(.99) for _ in range(1000)).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, at about 1000 samples, we have an estimate of the p99 with a reasonable amount of error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## So what's happening?\n",
    "\n",
    "Let's review what just happened. Two things are worth noting:\n",
    "\n",
    "1. Our small sample underestimated the real p99 by 10%!\n",
    "2. As we increased the sample size, we continued to underestimate. However, error decreased.\n",
    "\n",
    "The intuition for this phenomenon is simple. It's harder for samples to capture the full range of data since they only have a fraction of the p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## So who cares?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unavoidably, you'll explain this phenomenon to someone and they'll tell you that the effect is negligible. In some cases they may be right, so keep an open mind and remember what your requirements are.\n",
    "\n",
    "In most cases they are egregiously underestimating how much error is being introduced.\n",
    "\n",
    "Let's talk about a few real world cases."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
